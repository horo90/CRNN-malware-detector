import numpy as np
import os
import copy
import shutil

def softmax(a):
    b = np.exp(a - np.max(a))
    return b / np.sum(b)

def arithmetic_prob(ind):
    ind_shift = ind + 1.
    sum = np.sum(ind_shift)
    p = ind_shift / sum
    return p

def padding3(data, encode_len):
    length = len(data)
    data = data.astype(np.int32)

    if length % encode_len != 0:
        res = encode_len - (length % encode_len)
        data = np.concatenate((data, np.zeros((res))), 0)
    # print data.shape
    data = data.reshape((-1, encode_len))
    return data

def one_hot2(data, n_voca):
    n_voca += 1 # because of zero padding



def padding2(data, encode_len, max_len):
    lens = list()
    for d in data:
        lens.append(len(d))

    padded_data = list()
    seq_len = list()
    for d in data:
        # original
        if len(d) > max_len:
            d = d[:max_len]
        seq_len.append(len(d))
        res = max_len - len(d)
        d = np.array(d)
        pad = np.zeros((res), dtype=np.int32)
        d = np.concatenate((d, pad), 0)
        padded_data.append(d)

    padded_data = np.array(padded_data)
    # below 2 line is for original, not variation
    a, b = padded_data.shape
    padded_data = padded_data.reshape((a, -1, encode_len))

    return padded_data.astype(np.int32), (np.array(seq_len) / encode_len).astype(np.int32)

def one_hot(data, n_voca):
    a, b, c = data.shape
    tmp = np.zeros((a, b, c, n_voca))
    data = data - 1
    a, b, c = data.shape
    # this one hot encodding must be improved...
    for i in range(a):
        for j in range(b):
            for k in range(c):
                if data[i, j, k] != -1:
                    tmp[i, j, k, data[i, j, k]] = 1.
    a, b, c, d = tmp.shape
    tmp = tmp.reshape((a, b, c, d, 1))
    tmp = np.transpose(tmp, (0, 1, 3, 2, 4))
    return tmp

def padding1(data, encode_len):
    new_data = list()
    for d in data:
        new_paths = list()
        for path in d:
            mod = len(path) % encode_len
            path = np.array(path)
            if mod != 0:
                res = encode_len - mod
                pad = np.zeros(res, dtype=np.int32)
                path = np.concatenate((path, pad), 0)
            path = path.tolist()
            new_paths.append(path)
        new_data.append(new_paths)
    new_data = np.array(new_data)
    return new_data

def load_data(data_root, n_sampled_path, encode_len):
    types = os.listdir(data_root)
    normal_data = None
    abnormal_data = None

    n_data = 1000

    for t in types:
        tpath = os.path.join(data_root, t)
        dpath = os.path.join(tpath, 'data.npy')
        if t == 'normal':
            normal_data = np.load(dpath)[:n_data * n_sampled_path]
        else:
            abnormal_data = np.load(dpath)[:n_data * n_sampled_path]
    data = np.concatenate((normal_data, abnormal_data), 0)
    data = np.array(np.split(data, len(data) / n_sampled_path))
    labels = np.zeros((len(data) * n_sampled_path, 1))
    labels = np.array(np.split(labels, len(labels) / n_sampled_path))

    # first half are normal, last half are abnormal
    labels[: n_data, :, 0] = 0.
    labels[n_data:, :, 0] = 1.

    index = np.arange(len(data))
    np.random.shuffle(index)
    data = data[index]
    labels = labels[index]

    data = padding1(data, encode_len)
    actual_lens = list()
    for i in range(n_data * 2):
        lens = list()
        for j in range(n_sampled_path):
            lens.append(len(data[i, j]))
        actual_lens.append(lens)
    actual_lens = np.array(actual_lens).astype(np.int32)
    return data, labels, actual_lens

def load_top_inst():
    f = open('./top_inst.txt', 'r')
    top_inst = dict()
    while True:
        line = f.readline()
        if line is None or line == '' : break
        else:
            line = line.replace('\n', '').split('\t')
            top_inst.update({int(line[1]) : line[0]})
    f.close()
    return top_inst

def remove_non_pe(n_sampeled_path):
    remove_list = list()

    f = open('./no_pe.txt', 'r')
    while True:
        line = f.readline()
        if line is None or line == '':break
        else:
            line = line.replace('\r', '').replace('\n', '')
            if line not in remove_list: remove_list.append(line)
    f.close()

    f = open('./zero_len.txt', 'r')
    prev = None
    i = 0
    while True:
        line = f.readline()
        if line is None or line == '':break
        else:
            line = line.replace('\r', '').replace('\n', '')
            if prev is None or prev != line:
                prev = line
            elif prev == line:
                i += 1
                if i > int(n_sampeled_path / 2) and line not in remove_list: remove_list.append(line)

    f.close()

    print(remove_list)

    dont_remove = ['utils.py', 'Decompress.py', 'DetectionModel.py', 'IndexingInstruction.py', 'main.py', 'PathFinder.py']
    for file in remove_list:
        print('> ', file)
        for dir_name, sub_dirs, files in os.walk('./'):
            # if file in files:
            if any(file in f for f in files):
                ind = [i for i, s in enumerate(files) if file in s][0]
                os.remove(os.path.join(dir_name, files[ind]))
            if file in dir_name and not any(f in dir_name for f in dont_remove):
                shutil.rmtree(dir_name)
    os.remove('./no_pe.txt')
    os.remove('./zero_len.txt')

def padding4(data, actual_lens, encoded_len):
    max_len = np.max(actual_lens)
    res = encoded_len - max_len % encoded_len
    max_len += res

    padded_data = list()
    padded_lens = list()
    for i in range(len(data)):
        pad = np.zeros((max_len - actual_lens[i]), dtype=np.int32)
        padd_arr = np.concatenate((data[i], pad))
        padded_lens.append(actual_lens[i] + encoded_len - actual_lens[i] % encoded_len)
        padded_data.append(padd_arr)
    padded_data = np.array(padded_data)
    padded_lens = np.array(padded_lens)
    return padded_data, padded_lens, max_len